Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/02/20 08:37:40 INFO SparkContext: Running Spark version 1.5.2
17/02/20 08:37:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/02/20 08:37:40 INFO SecurityManager: Changing view acls to: iparask
17/02/20 08:37:40 INFO SecurityManager: Changing modify acls to: iparask
17/02/20 08:37:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(iparask); users with modify permissions: Set(iparask)
17/02/20 08:37:40 INFO Slf4jLogger: Slf4jLogger started
17/02/20 08:37:40 INFO Remoting: Starting remoting
17/02/20 08:37:41 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@198.202.112.83:41100]
17/02/20 08:37:41 INFO Utils: Successfully started service 'sparkDriver' on port 41100.
17/02/20 08:37:41 INFO SparkEnv: Registering MapOutputTracker
17/02/20 08:37:41 INFO SparkEnv: Registering BlockManagerMaster
17/02/20 08:37:41 INFO DiskBlockManager: Created local directory at /scratch/iparask/7737570/blockmgr-479ac493-7e43-4788-a82b-b4e8f7225b72
17/02/20 08:37:41 INFO MemoryStore: MemoryStore started with capacity 31.0 GB
17/02/20 08:37:41 INFO HttpFileServer: HTTP File server directory is /scratch/iparask/7737570/spark-a06c288f-af8b-4eff-80f5-a7050022e054/httpd-04a14ae9-8562-40c7-93b8-b8088a57e3cc
17/02/20 08:37:41 INFO HttpServer: Starting HTTP Server
17/02/20 08:37:41 INFO Utils: Successfully started service 'HTTP file server' on port 37426.
17/02/20 08:37:41 INFO SparkEnv: Registering OutputCommitCoordinator
17/02/20 08:37:41 INFO Utils: Successfully started service 'SparkUI' on port 4045.
17/02/20 08:37:41 INFO SparkUI: Started SparkUI at http://198.202.112.83:4045
17/02/20 08:37:41 INFO Utils: Copying /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py to /scratch/iparask/7737570/spark-a06c288f-af8b-4eff-80f5-a7050022e054/userFiles-0da9c77c-e979-4e79-8997-810b16845e1e/leaflet-finder-parallel-cc.py
17/02/20 08:37:41 INFO SparkContext: Added file file:/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py at http://198.202.112.83:37426/files/leaflet-finder-parallel-cc.py with timestamp 1487608661269
17/02/20 08:37:41 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
17/02/20 08:37:41 INFO AppClient$ClientEndpoint: Connecting to master spark://comet-23-49.sdsc.edu:7077...
17/02/20 08:37:41 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20170220083741-0000
17/02/20 08:37:41 INFO AppClient$ClientEndpoint: Executor added: app-20170220083741-0000/0 on worker-20170220083729-198.202.112.88-39384 (198.202.112.88:39384) with 24 cores
17/02/20 08:37:41 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170220083741-0000/0 on hostPort 198.202.112.88:39384 with 24 cores, 60.0 GB RAM
17/02/20 08:37:41 INFO AppClient$ClientEndpoint: Executor updated: app-20170220083741-0000/0 is now RUNNING
17/02/20 08:37:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42684.
17/02/20 08:37:41 INFO NettyBlockTransferService: Server created on 42684
17/02/20 08:37:41 INFO BlockManagerMaster: Trying to register BlockManager
17/02/20 08:37:41 INFO BlockManagerMasterEndpoint: Registering block manager 198.202.112.83:42684 with 31.0 GB RAM, BlockManagerId(driver, 198.202.112.83, 42684)
17/02/20 08:37:41 INFO BlockManagerMaster: Registered BlockManager
17/02/20 08:37:41 INFO AppClient$ClientEndpoint: Executor updated: app-20170220083741-0000/0 is now LOADING
17/02/20 08:37:41 INFO EventLoggingListener: Logging events to file:/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/./app-20170220083741-0000
17/02/20 08:37:41 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/02/20 08:37:42 INFO SparkContext: Starting job: reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78
17/02/20 08:37:42 INFO DAGScheduler: Got job 0 (reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78) with 16 output partitions
17/02/20 08:37:42 INFO DAGScheduler: Final stage: ResultStage 0(reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78)
17/02/20 08:37:42 INFO DAGScheduler: Parents of final stage: List()
17/02/20 08:37:42 INFO DAGScheduler: Missing parents: List()
17/02/20 08:37:42 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[1] at reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78), which has no missing parents
17/02/20 08:37:42 INFO MemoryStore: ensureFreeSpace(5464) called with curMem=0, maxMem=33339683635
17/02/20 08:37:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.3 KB, free 31.0 GB)
17/02/20 08:37:42 INFO MemoryStore: ensureFreeSpace(3577) called with curMem=5464, maxMem=33339683635
17/02/20 08:37:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.5 KB, free 31.0 GB)
17/02/20 08:37:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 198.202.112.83:42684 (size: 3.5 KB, free: 31.0 GB)
17/02/20 08:37:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
17/02/20 08:37:42 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 0 (PythonRDD[1] at reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78)
17/02/20 08:37:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 16 tasks
17/02/20 08:37:43 INFO SparkDeploySchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@198.202.112.88:38553/user/Executor#868064152]) with ID 0
17/02/20 08:37:43 WARN TaskSetManager: Stage 0 contains a task of very large size (770 KB). The maximum recommended task size is 100 KB.
17/02/20 08:37:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 198.202.112.88, PROCESS_LOCAL, 788775 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 198.202.112.88, PROCESS_LOCAL, 788776 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 198.202.112.88, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 198.202.112.88, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 198.202.112.88, PROCESS_LOCAL, 788776 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 198.202.112.88, PROCESS_LOCAL, 788777 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 198.202.112.88, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 198.202.112.88, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 198.202.112.88, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 198.202.112.88, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 198.202.112.88, PROCESS_LOCAL, 788781 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 198.202.112.88, PROCESS_LOCAL, 788781 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 198.202.112.88, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 198.202.112.88, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 198.202.112.88, PROCESS_LOCAL, 788781 bytes)
17/02/20 08:37:43 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 198.202.112.88, PROCESS_LOCAL, 788781 bytes)
17/02/20 08:37:43 INFO BlockManagerMasterEndpoint: Registering block manager 198.202.112.88:43502 with 31.0 GB RAM, BlockManagerId(0, 198.202.112.88, 43502)
17/02/20 08:37:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 198.202.112.88:43502 (size: 3.5 KB, free: 31.0 GB)
17/02/20 08:37:52 WARN TaskSetManager: Lost task 3.0 in stage 0.0 (TID 3, 198.202.112.88): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:203)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:139)
	... 11 more

17/02/20 08:37:52 INFO TaskSetManager: Starting task 3.1 in stage 0.0 (TID 16, 198.202.112.88, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:37:52 WARN TaskSetManager: Lost task 4.0 in stage 0.0 (TID 4, 198.202.112.88): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

17/02/20 08:37:52 INFO TaskSetManager: Starting task 4.1 in stage 0.0 (TID 17, 198.202.112.88, PROCESS_LOCAL, 788776 bytes)
17/02/20 08:37:53 WARN TaskSetManager: Lost task 4.1 in stage 0.0 (TID 17, 198.202.112.88): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
  File "/home/iparask/radical.pilot.sandbox/ve_comet/lib/python2.7/site-packages/scipy/spatial/distance.py", line 2037, in cdist
    dm = np.zeros((mA, mB), dtype=np.double)
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

17/02/20 08:37:53 INFO TaskSetManager: Starting task 4.2 in stage 0.0 (TID 18, 198.202.112.88, PROCESS_LOCAL, 788776 bytes)
17/02/20 08:37:53 INFO TaskSetManager: Lost task 3.1 in stage 0.0 (TID 16) on executor 198.202.112.88: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
  File "/home/iparask/radical.pilot.sandbox/ve_comet/lib/python2.7/site-packages/scipy/spatial/distance.py", line 2037, in cdist
    dm = np.zeros((mA, mB), dtype=np.double)
MemoryError
) [duplicate 1]
17/02/20 08:37:53 INFO TaskSetManager: Starting task 3.2 in stage 0.0 (TID 19, 198.202.112.88, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:37:53 INFO TaskSetManager: Lost task 4.2 in stage 0.0 (TID 18) on executor 198.202.112.88: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
  File "/home/iparask/radical.pilot.sandbox/ve_comet/lib/python2.7/site-packages/scipy/spatial/distance.py", line 2037, in cdist
    dm = np.zeros((mA, mB), dtype=np.double)
MemoryError
) [duplicate 2]
17/02/20 08:37:53 INFO TaskSetManager: Starting task 4.3 in stage 0.0 (TID 20, 198.202.112.88, PROCESS_LOCAL, 788776 bytes)
17/02/20 08:37:53 INFO TaskSetManager: Lost task 3.2 in stage 0.0 (TID 19) on executor 198.202.112.88: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
  File "/home/iparask/radical.pilot.sandbox/ve_comet/lib/python2.7/site-packages/scipy/spatial/distance.py", line 2037, in cdist
    dm = np.zeros((mA, mB), dtype=np.double)
MemoryError
) [duplicate 3]
17/02/20 08:37:53 INFO TaskSetManager: Starting task 3.3 in stage 0.0 (TID 21, 198.202.112.88, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:41:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 235331 ms on 198.202.112.88 (1/16)
17/02/20 08:41:39 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 235913 ms on 198.202.112.88 (2/16)
17/02/20 08:41:39 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 236235 ms on 198.202.112.88 (3/16)
17/02/20 08:41:40 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 236888 ms on 198.202.112.88 (4/16)
17/02/20 08:41:40 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 237257 ms on 198.202.112.88 (5/16)
17/02/20 08:41:42 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 239488 ms on 198.202.112.88 (6/16)
17/02/20 08:41:44 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 241430 ms on 198.202.112.88 (7/16)
17/02/20 08:41:46 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 242921 ms on 198.202.112.88 (8/16)
17/02/20 08:41:46 INFO TaskSetManager: Finished task 3.3 in stage 0.0 (TID 21) in 232580 ms on 198.202.112.88 (9/16)
17/02/20 08:41:46 INFO TaskSetManager: Finished task 4.3 in stage 0.0 (TID 20) in 232630 ms on 198.202.112.88 (10/16)
17/02/20 08:41:46 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 243410 ms on 198.202.112.88 (11/16)
17/02/20 08:41:49 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 246556 ms on 198.202.112.88 (12/16)
17/02/20 08:41:53 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 250650 ms on 198.202.112.88 (13/16)
17/02/20 08:41:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 252857 ms on 198.202.112.88 (14/16)
17/02/20 08:41:56 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 253100 ms on 198.202.112.88 (15/16)
17/02/20 08:41:56 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 253361 ms on 198.202.112.88 (16/16)
17/02/20 08:41:56 INFO DAGScheduler: ResultStage 0 (reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78) finished in 254.472 s
17/02/20 08:41:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/02/20 08:41:56 INFO DAGScheduler: Job 0 finished: reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_1-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78, took 254.600286 s
17/02/20 08:41:56 INFO SparkContext: Invoking stop() from shutdown hook
17/02/20 08:41:56 INFO SparkUI: Stopped Spark web UI at http://198.202.112.83:4045
17/02/20 08:41:56 INFO DAGScheduler: Stopping DAGScheduler
17/02/20 08:41:56 INFO SparkDeploySchedulerBackend: Shutting down all executors
17/02/20 08:41:56 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
17/02/20 08:41:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/02/20 08:41:56 INFO MemoryStore: MemoryStore cleared
17/02/20 08:41:56 INFO BlockManager: BlockManager stopped
17/02/20 08:41:56 INFO BlockManagerMaster: BlockManagerMaster stopped
17/02/20 08:41:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/02/20 08:41:56 INFO SparkContext: Successfully stopped SparkContext
17/02/20 08:41:56 INFO ShutdownHookManager: Shutdown hook called
17/02/20 08:41:56 INFO ShutdownHookManager: Deleting directory /scratch/iparask/7737570/spark-a06c288f-af8b-4eff-80f5-a7050022e054
