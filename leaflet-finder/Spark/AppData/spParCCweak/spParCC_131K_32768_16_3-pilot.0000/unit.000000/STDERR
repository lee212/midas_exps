Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/02/20 08:53:05 INFO SparkContext: Running Spark version 1.5.2
17/02/20 08:53:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/02/20 08:53:05 INFO SecurityManager: Changing view acls to: iparask
17/02/20 08:53:05 INFO SecurityManager: Changing modify acls to: iparask
17/02/20 08:53:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(iparask); users with modify permissions: Set(iparask)
17/02/20 08:53:05 INFO Slf4jLogger: Slf4jLogger started
17/02/20 08:53:05 INFO Remoting: Starting remoting
17/02/20 08:53:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@198.202.116.254:34588]
17/02/20 08:53:05 INFO Utils: Successfully started service 'sparkDriver' on port 34588.
17/02/20 08:53:05 INFO SparkEnv: Registering MapOutputTracker
17/02/20 08:53:05 INFO SparkEnv: Registering BlockManagerMaster
17/02/20 08:53:05 INFO DiskBlockManager: Created local directory at /scratch/iparask/7737656/blockmgr-9524a4b7-2e8d-4ba8-a207-564cb36468cd
17/02/20 08:53:05 INFO MemoryStore: MemoryStore started with capacity 31.0 GB
17/02/20 08:53:05 INFO HttpFileServer: HTTP File server directory is /scratch/iparask/7737656/spark-2ce58ee3-ca80-4d35-8e1d-4d907dfdf45e/httpd-2dbc9a64-3ce0-4030-8719-e03ac65876cf
17/02/20 08:53:05 INFO HttpServer: Starting HTTP Server
17/02/20 08:53:05 INFO Utils: Successfully started service 'HTTP file server' on port 38942.
17/02/20 08:53:05 INFO SparkEnv: Registering OutputCommitCoordinator
17/02/20 08:53:05 INFO Utils: Successfully started service 'SparkUI' on port 4045.
17/02/20 08:53:05 INFO SparkUI: Started SparkUI at http://198.202.116.254:4045
17/02/20 08:53:06 INFO Utils: Copying /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py to /scratch/iparask/7737656/spark-2ce58ee3-ca80-4d35-8e1d-4d907dfdf45e/userFiles-bd965107-7298-4f8b-95c6-413339e65599/leaflet-finder-parallel-cc.py
17/02/20 08:53:06 INFO SparkContext: Added file file:/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py at http://198.202.116.254:38942/files/leaflet-finder-parallel-cc.py with timestamp 1487609586057
17/02/20 08:53:06 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
17/02/20 08:53:06 INFO AppClient$ClientEndpoint: Connecting to master spark://comet-12-10.sdsc.edu:7077...
17/02/20 08:53:06 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20170220085306-0000
17/02/20 08:53:06 INFO AppClient$ClientEndpoint: Executor added: app-20170220085306-0000/0 on worker-20170220085255-198.202.117.16-42657 (198.202.117.16:42657) with 24 cores
17/02/20 08:53:06 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170220085306-0000/0 on hostPort 198.202.117.16:42657 with 24 cores, 60.0 GB RAM
17/02/20 08:53:06 INFO AppClient$ClientEndpoint: Executor updated: app-20170220085306-0000/0 is now RUNNING
17/02/20 08:53:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38358.
17/02/20 08:53:06 INFO NettyBlockTransferService: Server created on 38358
17/02/20 08:53:06 INFO BlockManagerMaster: Trying to register BlockManager
17/02/20 08:53:06 INFO BlockManagerMasterEndpoint: Registering block manager 198.202.116.254:38358 with 31.0 GB RAM, BlockManagerId(driver, 198.202.116.254, 38358)
17/02/20 08:53:06 INFO BlockManagerMaster: Registered BlockManager
17/02/20 08:53:06 INFO AppClient$ClientEndpoint: Executor updated: app-20170220085306-0000/0 is now LOADING
17/02/20 08:53:06 INFO EventLoggingListener: Logging events to file:/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/./app-20170220085306-0000
17/02/20 08:53:06 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/02/20 08:53:06 INFO SparkContext: Starting job: reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78
17/02/20 08:53:06 INFO DAGScheduler: Got job 0 (reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78) with 16 output partitions
17/02/20 08:53:06 INFO DAGScheduler: Final stage: ResultStage 0(reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78)
17/02/20 08:53:06 INFO DAGScheduler: Parents of final stage: List()
17/02/20 08:53:06 INFO DAGScheduler: Missing parents: List()
17/02/20 08:53:06 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[1] at reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78), which has no missing parents
17/02/20 08:53:06 INFO MemoryStore: ensureFreeSpace(5464) called with curMem=0, maxMem=33339683635
17/02/20 08:53:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.3 KB, free 31.0 GB)
17/02/20 08:53:06 INFO MemoryStore: ensureFreeSpace(3577) called with curMem=5464, maxMem=33339683635
17/02/20 08:53:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.5 KB, free 31.0 GB)
17/02/20 08:53:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 198.202.116.254:38358 (size: 3.5 KB, free: 31.0 GB)
17/02/20 08:53:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:861
17/02/20 08:53:06 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 0 (PythonRDD[1] at reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78)
17/02/20 08:53:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 16 tasks
17/02/20 08:53:07 INFO SparkDeploySchedulerBackend: Registered executor: AkkaRpcEndpointRef(Actor[akka.tcp://sparkExecutor@198.202.117.16:36085/user/Executor#-204983240]) with ID 0
17/02/20 08:53:08 WARN TaskSetManager: Stage 0 contains a task of very large size (770 KB). The maximum recommended task size is 100 KB.
17/02/20 08:53:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 198.202.117.16, PROCESS_LOCAL, 788776 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 198.202.117.16, PROCESS_LOCAL, 788777 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 198.202.117.16, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, 198.202.117.16, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, 198.202.117.16, PROCESS_LOCAL, 788777 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, 198.202.117.16, PROCESS_LOCAL, 788778 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, 198.202.117.16, PROCESS_LOCAL, 788780 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, 198.202.117.16, PROCESS_LOCAL, 788780 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, 198.202.117.16, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, 198.202.117.16, PROCESS_LOCAL, 788780 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, 198.202.117.16, PROCESS_LOCAL, 788782 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, 198.202.117.16, PROCESS_LOCAL, 788782 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, 198.202.117.16, PROCESS_LOCAL, 788779 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, 198.202.117.16, PROCESS_LOCAL, 788780 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, 198.202.117.16, PROCESS_LOCAL, 788782 bytes)
17/02/20 08:53:08 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, 198.202.117.16, PROCESS_LOCAL, 788782 bytes)
17/02/20 08:53:08 INFO BlockManagerMasterEndpoint: Registering block manager 198.202.117.16:42774 with 31.0 GB RAM, BlockManagerId(0, 198.202.117.16, 42774)
17/02/20 08:53:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 198.202.117.16:42774 (size: 3.5 KB, free: 31.0 GB)
17/02/20 08:53:17 WARN TaskSetManager: Lost task 15.0 in stage 0.0 (TID 15, 198.202.117.16): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:139)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

17/02/20 08:53:17 INFO TaskSetManager: Starting task 15.1 in stage 0.0 (TID 16, 198.202.117.16, PROCESS_LOCAL, 788782 bytes)
17/02/20 08:53:18 WARN TaskSetManager: Lost task 4.0 in stage 0.0 (TID 4, 198.202.117.16): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

17/02/20 08:53:18 INFO TaskSetManager: Starting task 4.1 in stage 0.0 (TID 17, 198.202.117.16, PROCESS_LOCAL, 788777 bytes)
17/02/20 08:53:18 WARN TaskSetManager: Lost task 4.1 in stage 0.0 (TID 17, 198.202.117.16): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
  File "/home/iparask/radical.pilot.sandbox/ve_comet/lib/python2.7/site-packages/scipy/spatial/distance.py", line 2037, in cdist
    dm = np.zeros((mA, mB), dtype=np.double)
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

17/02/20 08:53:18 INFO TaskSetManager: Starting task 4.2 in stage 0.0 (TID 18, 198.202.117.16, PROCESS_LOCAL, 788777 bytes)
17/02/20 08:53:18 INFO TaskSetManager: Lost task 15.1 in stage 0.0 (TID 16) on executor 198.202.117.16: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/spark-1.5.2/python/lib/pyspark.zip/pyspark/rdd.py", line 794, in func
  File "/home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py", line 20, in find_partial_connected_components
    distances = (cdist(window[0],window[1])<cutoff)  # check indexes
  File "/home/iparask/radical.pilot.sandbox/ve_comet/lib/python2.7/site-packages/scipy/spatial/distance.py", line 2037, in cdist
    dm = np.zeros((mA, mB), dtype=np.double)
MemoryError
) [duplicate 1]
17/02/20 08:53:18 INFO TaskSetManager: Starting task 15.2 in stage 0.0 (TID 19, 198.202.117.16, PROCESS_LOCAL, 788782 bytes)
17/02/20 08:53:19 INFO TaskSetManager: Lost task 7.0 in stage 0.0 (TID 7) on executor 198.202.117.16: java.net.SocketException (Connection reset) [duplicate 1]
17/02/20 08:53:19 INFO TaskSetManager: Starting task 7.1 in stage 0.0 (TID 20, 198.202.117.16, PROCESS_LOCAL, 788780 bytes)
17/02/20 08:57:04 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 236575 ms on 198.202.117.16 (1/16)
17/02/20 08:57:04 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 236599 ms on 198.202.117.16 (2/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 237024 ms on 198.202.117.16 (3/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 237248 ms on 198.202.117.16 (4/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 237397 ms on 198.202.117.16 (5/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 237435 ms on 198.202.117.16 (6/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 237455 ms on 198.202.117.16 (7/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 237559 ms on 198.202.117.16 (8/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 237705 ms on 198.202.117.16 (9/16)
17/02/20 08:57:05 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 237789 ms on 198.202.117.16 (10/16)
17/02/20 08:57:12 INFO TaskSetManager: Finished task 4.2 in stage 0.0 (TID 18) in 233882 ms on 198.202.117.16 (11/16)
17/02/20 08:57:12 INFO TaskSetManager: Finished task 7.1 in stage 0.0 (TID 20) in 232996 ms on 198.202.117.16 (12/16)
17/02/20 08:57:20 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 252385 ms on 198.202.117.16 (13/16)
17/02/20 08:57:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 253389 ms on 198.202.117.16 (14/16)
17/02/20 08:57:21 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 253729 ms on 198.202.117.16 (15/16)
17/02/20 08:57:26 INFO TaskSetManager: Finished task 15.2 in stage 0.0 (TID 19) in 247965 ms on 198.202.117.16 (16/16)
17/02/20 08:57:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/02/20 08:57:26 INFO DAGScheduler: ResultStage 0 (reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78) finished in 259.925 s
17/02/20 08:57:26 INFO DAGScheduler: Job 0 finished: reduce at /home/iparask/radical.pilot.sandbox/spParCC_131K__32768_16_3-pilot.0000/unit.000000/leaflet-finder-parallel-cc.py:78, took 260.049061 s
17/02/20 08:57:26 INFO SparkContext: Invoking stop() from shutdown hook
17/02/20 08:57:27 INFO SparkUI: Stopped Spark web UI at http://198.202.116.254:4045
17/02/20 08:57:27 INFO DAGScheduler: Stopping DAGScheduler
17/02/20 08:57:27 INFO SparkDeploySchedulerBackend: Shutting down all executors
17/02/20 08:57:27 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
17/02/20 08:57:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/02/20 08:57:27 INFO MemoryStore: MemoryStore cleared
17/02/20 08:57:27 INFO BlockManager: BlockManager stopped
17/02/20 08:57:27 INFO BlockManagerMaster: BlockManagerMaster stopped
17/02/20 08:57:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/02/20 08:57:27 INFO SparkContext: Successfully stopped SparkContext
17/02/20 08:57:27 INFO ShutdownHookManager: Shutdown hook called
17/02/20 08:57:27 INFO ShutdownHookManager: Deleting directory /scratch/iparask/7737656/spark-2ce58ee3-ca80-4d35-8e1d-4d907dfdf45e
